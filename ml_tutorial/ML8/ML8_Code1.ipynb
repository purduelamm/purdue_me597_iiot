{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCtYNxU1obTp"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDRyFk_aogGp"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUNz_xYMmjm5"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRFcx-HclW7t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie0qFvRImqWJ"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oadW8SNVmuJc"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter related to loading our dataset\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "# We are going to download open-sourced dataset to demonstrate transfer learning\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True, cache_subdir='/content/')\n",
    "PATH = f'{path_to_zip}/cats_and_dogs_filtered'\n",
    "\n",
    "# Generate tf.data.Datset for training and validation dataset\n",
    "# This allows us to efficiently load batch of data to our NN model for training and validation\n",
    "# FYI: https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, shuffle=True, image_size=IMG_SIZE)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir, shuffle=True, image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMsHdf_SqI-5"
   },
   "source": [
    "## Dataset Splitting\n",
    "\n",
    "Conventionally, researchers and engineers split the entire dataset into three groups: 1) Train dataset, 2) Validation dataset, 3) Test dataset. Typically, 1) is directly utilized to train our NN while 2) is used to log how the model learns during the training. On the other hand, 3) is literally used to test how well the model generalizes across new dataset, which is an important performance metric of NN models.\n",
    "\n",
    "**Now, the question is: why are we introducing 2) during the training if it doesn't even used for the actual training process?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvPS6WJ6qIJO"
   },
   "outputs": [],
   "source": [
    "# The original dataset doesn't contain a test set.\n",
    "# So, we are going to create one. To do so, we determine how many batches of data are available in the validation set using tf.data.experimental.cardinality.\n",
    "# We will use 20% of the validation data as a test set.\n",
    "\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "print(f'# of validation batches: {tf.data.experimental.cardinality(validation_dataset)}')\n",
    "print(f'# of test batches: {tf.data.experimental.cardinality(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCSp281MphhG"
   },
   "source": [
    "## Data Inspection & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqCFs0DJpwAd"
   },
   "outputs": [],
   "source": [
    "# Let's visualize several images in our dataset\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkiPbF75uRdx"
   },
   "source": [
    "## Rescale Pixel Values\n",
    "\n",
    "In a moment, we will download `tf.keras.applications.MobileNetV2` for use as your base model. This model expects pixel values in `[-1, 1]`, but at this point, the pixel values in your images are in `[0, 255]`. Hence, we need to adjust this for training our own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkoB9rDhunDj"
   },
   "outputs": [],
   "source": [
    "# To rescale them, we use the preprocessing method included with the model.\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XY-ymP2uvlI"
   },
   "source": [
    "## Base Model (i.e., Backbone) Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddggCilLu0dV"
   },
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE = IMG_SIZE + (3,) # (160, 160, 3) -> RGB image\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbColBRXvNtB"
   },
   "source": [
    "## Method 1. Feature Extraction\n",
    "\n",
    "Feature Extraction is a method where you use a base model (i.e., **backbone**) as a generic feature extractor. This method requires the least amount of effort to generate your own NN as you only train a **head** for your own application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oICuzdSuvNWV"
   },
   "outputs": [],
   "source": [
    "# This will \"freeze\" weights and biases in our base model.\n",
    "# In other words, there will be no backpropagation of the loss graidents to update weights and biases in the NN.\n",
    "base_model.trainable =\n",
    "\n",
    "# Now, let's design our own classification head for our own application\n",
    "# When generating your own NN model, make sure that intermediate dimenions between layers are correct!\n",
    "# Let's first check output dimension of the base_model\n",
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)\n",
    "\n",
    "# Since we are going to design a simple binary classifiation model, we will use average pooling layer to obtain a global feature of an inpute image.\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)\n",
    "\n",
    "# Then, make sure that we get the expected shape after going to our classification head.\n",
    "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)\n",
    "\n",
    "# Finally, let's build our model.\n",
    "# We will also check whether our model works as expected. We will use a dummy image to test the model.\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sg1K8rpaB5dD"
   },
   "outputs": [],
   "source": [
    "# Check how many parameters are trainable\n",
    "model.summary()\n",
    "len(model.trainable_variables)\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9CTFzOkxJrZ"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijrNc3NPxVTY"
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001 # Another important hyperparameter to train our model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])\n",
    "\n",
    "\n",
    "# Let's see how this process will improve our NN after 10 epochs of training.\n",
    "epochs = 10\n",
    "loss0, accuracy0 = model.evaluate(validation_dataset)\n",
    "\n",
    "print(f\"initial loss: {loss0:.2f}\")\n",
    "print(f\"initial accuracy: {accuracy0:.2f}\")\n",
    "\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)\n",
    "\n",
    "# Visualization of loss and accuracy during the training process\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzgzDm2hBPeH"
   },
   "outputs": [],
   "source": [
    "# Now, let's check how the model works on the test dataset\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)\n",
    "\n",
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPvyldJSvJRUkpNozOApo27",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
