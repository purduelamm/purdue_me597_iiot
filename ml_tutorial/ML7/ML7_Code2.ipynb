{"cells":[{"cell_type":"markdown","metadata":{"id":"lwy-PAUHopvl"},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWwdLjHnopvm"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7qzTc5fopvm"},"outputs":[],"source":["# Import 'Tensorflow' pakage\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Check the version of tensorflow\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgFM50ixjXdk"},"outputs":[],"source":["# Check if a GPU(in Google server) is allocated\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qSURm6XzqZNp"},"outputs":[],"source":["# Acess to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":[".\n","\n",".\n","\n",".\n","# Load Raw Data and Extract Acceleration Data\n","- Generate single array that consists of every acceleration data (normal and abnormal)"],"metadata":{"id":"2Bi1q0lacPkz"}},{"cell_type":"code","source":["AccData_pd_load = pd.read_csv('https://github.com/purduelamm/purdue_me597_iiot_online/blob/main/ml_tutorial/Dataset_Acc/AccData.csv?raw=true').iloc[:,1:]\n","AccData_pd_load.shape"],"metadata":{"id":"gKrNKfx-5Ykg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AccData = np.array(AccData_pd_load)\n","AccData.shape"],"metadata":{"id":"NLyM1oqK6c65"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Convert Acceleration Data into Spectrogram by STFT"],"metadata":{"id":"nsWTe-KrxQQ6"}},{"cell_type":"markdown","source":["[Tip]\n","\n","You can define the size of spectrogram (resolution of time and frequency)\n","\n","by adjusting 'Number of samples(N) per segment (nperseg)' and 'Number of samples(N) for overlap'"],"metadata":{"id":"HqdlupjHxZVB"}},{"cell_type":"code","source":["from scipy import signal\n","\n","Fs = 12800  # Sampling Frequency\n","f,t,AccSTFT = signal.spectrogram(AccData, Fs, nperseg = 78, noverlap = 10)\n","AccSTFT.shape"],"metadata":{"id":"ocnP5QWzcOB-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zps3qPZH0CZN"},"source":[".\n","\n",".\n","\n",".\n","\n",".\n","\n","## Split Training & Test Data\n","- Use 'train_test_split' function\n","- It randomly samples the training and testing data according to the designated ratio."]},{"cell_type":"code","source":["NoOfData = 180\n","\n","NormalSet   = AccSTFT[:NoOfData]\n","AbnormalSet = AccSTFT[NoOfData:]\n","\n","NoOfSensor  = 1\n","NormalSet   = NormalSet.reshape(NormalSet.shape[0], NormalSet.shape[1], NormalSet.shape[2], NoOfSensor)\n","AbnormalSet = AbnormalSet.reshape(AbnormalSet.shape[0], AbnormalSet.shape[1], AbnormalSet.shape[2], NoOfSensor)\n","\n","NormalSet.shape, AbnormalSet.shape"],"metadata":{"id":"sSHeYisJX8SZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection    import train_test_split\n","\n","# Designate test data ratio\n","TestData_Ratio = 0.2\n","\n","TrainData_Nor, TestData_Nor = train_test_split(NormalSet  , test_size=TestData_Ratio, random_state=777)\n","TrainData_Abn, TestData_Abn = train_test_split(AbnormalSet, test_size=TestData_Ratio, random_state=777)\n","\n","print(TrainData_Nor.shape, TestData_Nor.shape)\n","print(TrainData_Abn.shape, TestData_Abn.shape)"],"metadata":{"id":"T_-DpjKpX7-3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Labling (One-hot Encoding)\n","- Use 'np.zeros' and 'np.ones'\n","- '[1,0]' refers to 'Normal' and '[1,0]' refers to 'Abnormal' in this tutorial"],"metadata":{"id":"VlO_u2CjlvZY"}},{"cell_type":"code","source":["TrainLabel_Nor = np.zeros((TrainData_Nor.shape[0],2))\n","TrainLabel_Abn = np.ones( (TrainData_Abn.shape[0],2))\n","TestLabel_Nor  = np.zeros((TestData_Nor.shape[0],2))\n","TestLabel_Abn  = np.ones( (TestData_Abn.shape[0],2))\n","\n","TrainLabel_Nor[:,0] = 1  # [1,0]: Normal\n","TrainLabel_Abn[:,0] = 0  # [0,1]: Abnormal\n","TestLabel_Nor[:,0]  = 1  # [1,0]: Normal\n","TestLabel_Abn[:,0]  = 0  # [0,1]: Abnormal\n","\n","print(TrainLabel_Nor.shape, TestLabel_Nor.shape)\n","print(TrainLabel_Abn.shape, TestLabel_Abn.shape)"],"metadata":{"id":"j4-2rzxQboWF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data and Label Preparation"],"metadata":{"id":"SR24Ptr1l9mY"}},{"cell_type":"code","source":["TrainData  = np.concatenate([TrainData_Nor , TrainData_Abn ], axis=0)\n","TestData   = np.concatenate([TestData_Nor  , TestData_Abn  ], axis=0)\n","TrainLabel = np.concatenate([TrainLabel_Nor, TrainLabel_Abn], axis=0)\n","TestLabel  = np.concatenate([TestLabel_Nor , TestLabel_Abn ], axis=0)\n","\n","print(TrainData.shape,  TestData.shape)\n","print(TrainLabel.shape, TestLabel.shape)"],"metadata":{"id":"HnZh6FJKX7Bn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[".\n","\n",".\n","\n",".\n","\n",".\n","\n","."],"metadata":{"id":"Ea-DpZP9TcaQ"}},{"cell_type":"markdown","metadata":{"id":"TwgRfDG6opvn"},"source":["### [Main hyperparameters of CNN]\n","\n","1. **Number of Convolutional Layers**: The number of convolutional layers in a CNN determines the network's ability to capture hierarchical features of the input data. Each layer can be thought of as a level of abstraction, with initial layers capturing basic features like edges and textures, and deeper layers capturing more complex features. The depth of the network is crucial for learning complex patterns, but increasing the number of convolutional layers increases the computational cost and the risk of overfitting. The depth $D$ of the network is directly related to the number of convolutional layers.\n","\n",".\n","\n","2. **Filter Size in Convolutional Layers**: The size of the filters (or kernels) in convolutional layers affects the area of input data that each filter covers. Common filter sizes include [3x3],[5x5], and [7x7]. Smaller filters can capture finer details of the input image, while larger filters capture broader features but with less spatial resolution. The choice of filter size ($F$) is a trade-off between capturing detailed features and computational efficiency.\n","\n",".\n","\n","3. **Number of Filters per Convolutional Layer**: The number of filters in a convolutional layer determines how many features are captured from the input data at that layer. More filters allow the network to capture a wider variety of features, enhancing the network's ability to recognize different patterns in the data. However, increasing the number of filters ($N$) also increases the computational complexity and the model's capacity, potentially leading to overfitting.\n","\n",".\n","\n","4. **Type of Pooling Layers**: Pooling layers reduce the spatial dimensions of the input feature maps, making the network more efficient and reducing the sensitivity to the exact location of features in the input data. There are two main types of pooling:\n","Max Pooling: Selects the maximum value from each patch of the feature map.\n","Average Pooling: Computes the average value of each patch of the feature map.\n","Pooling operations are typically applied with a [2x2] window, reducing the spatial dimensions of the feature maps by a factor of 2. This downsampling effect helps to make the model more robust to variations in the position of features within the input data.\n","\n",".\n","\n","5. **Stride and Padding**: Stride ($S$) and padding ($P$) are hyperparameters that affect the size of the output feature maps produced by convolutional and pooling layers. Stride refers to the number of pixels by which the filter moves across the input image. A stride of 1 means the filter moves one pixel at a time, while a higher stride results in larger movements. Padding involves adding extra pixels around the input image to allow the convolutional operation to be applied more fully at the borders of the image. Proper selection of stride and padding is essential for controlling the dimensions of the output feature maps and ensuring that important information is not lost at the edges of the image.\n","\n",".\n","\n","6. **Activation functions**: Similar to ANNs, activation functions in CNNs introduce non-linearity, enabling the network to learn complex patterns and representations. Common activation functions include:\n","  - Sigmoid: $f(x) = \\frac{1}{1 + e^{-x}}$\n","  - Hyperbolic Tangent (tanh): $f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n","  - Rectified Linear Unit (ReLU): $f(x) = max(0, x)$\n","  - Leaky ReLU: $f(x) = max(\\alpha x, x)$, where $\\alpha$ is a small constant (e.g., 0.01)\n","\n",".\n","\n","7. **Learning rate, Optimizer, Loss function, and Epochs**: The considerations for learning rate, optimizer, loss function, and epochs in CNNs are similar to those in ANNs. These hyperparameters play a critical role in the training process, affecting the speed and quality of convergence to the optimal model weights. The choice of optimizer (e.g., Adam, SGD) and loss function (e.g., Cross-Entropy Loss) is dictated by the specific task and data at hand. The learning rate controls the update magnitude of the model weights during training, and the number of epochs determines how many times the entire training dataset is passed through the network."]},{"cell_type":"markdown","source":["### Prepare lists of hyperparameters for grid search"],"metadata":{"id":"OFMr59wnAGGJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBYZBbydopvn"},"outputs":[],"source":["# Hyperparameters for grid search\n","param_FiltS = [3, 5] # filter(kernel) size (only convolution layer)\n","param_FiltN = [2, 4] # number of filters   (only convolution layer)\n","param_Strid = [1, 2] # stride              (only convolution layer)\n","\n","# Fixed hyperparameters\n","noOfNeuron    = 10\n","learningRate  = 0.0001\n","Epoch         = 1000\n","\n","# Calculate the number of cases\n","NoOfCases = len(param_FiltS) * len(param_FiltN) * len(param_Strid)\n","NoOfCases"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZvrun9Oopvo"},"outputs":[],"source":["# Complete this function\n","def CNN_model(input_data, noOfNeuron, learningRate, filterSize, numOfFilters, stride):\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","    return model"]},{"cell_type":"code","source":["# Create an empty dataframe to store the accuracy results\n","Accuracy_df = pd.DataFrame(np.zeros(shape=(NoOfCases , 4)),\n","                           columns=['filter size', 'number of filters', 'stride', 'Accuracy'])\n","Accuracy_df"],"metadata":{"id":"_DdNsv1GDmxP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gISsVxFAopvo"},"source":["### Train the CNN models with different combinations of hyperparameters and save them"]},{"cell_type":"code","source":["# Initialize a count value to store the performance of each model\n","cnt = 0\n","\n","# Iterate through all possible combinations of filter size, filter number, and stride\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Display the resulting dataframe with model performances\n","Accuracy_df"],"metadata":{"id":"PfrdlSMeDx9E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Confirm the grid search results"],"metadata":{"id":"jCTJxmOuboMM"}},{"cell_type":"code","source":["# Sort the Accuracy_df by 'Accuracy' column in descending order\n","Accuracy_df_sorted = Accuracy_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n","\n","# Output the best case\n","Best_FiltS = int(Accuracy_df_sorted.iloc[0, 0])\n","Best_FiltN = int(Accuracy_df_sorted.iloc[0, 1])\n","Best_Strid = int(Accuracy_df_sorted.iloc[0, 2])\n","\n","print(f\"[Best case]\\n\" +\n","      f\"Filter size   : [{Best_FiltS},{Best_FiltS}]\\n\" +\n","      f\"Num of Filters: {Best_FiltN}\\n\" +\n","      f\"Strides       : {Best_Strid}\\n\" +\n","      \"Accuracy: %.2f\" % (Accuracy_df_sorted.iloc[0, 3]))"],"metadata":{"id":"zxNrgSgLkycD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate mean and standard deviation accuracy for each filter size\n","mean_accuracy_FiltS = Accuracy_df.groupby(['filter size'])['Accuracy'].agg(['mean', 'std']).reset_index()\n","mean_accuracy_FiltS"],"metadata":{"id":"ndmF-k2NSWvc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate mean and standard deviation of accuracy for each number of filter\n","mean_accuracy_FiltN = Accuracy_df.groupby(['number of filters'])['Accuracy'].agg(['mean', 'std']).reset_index()\n","mean_accuracy_FiltN"],"metadata":{"id":"cA63DIElTXsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate mean and standard deviation of accuracy for each stride\n","mean_accuracy_Strid = Accuracy_df.groupby(['stride'])['Accuracy'].agg(['mean', 'std']).reset_index()\n","mean_accuracy_Strid"],"metadata":{"id":"s8ueF8DETYSy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [Confusion matrix] for the best CNN model\n","\n","- A table that visualizes the performance of a classification model by displaying the number of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions. The rows represent the true class labels, while the columns represent the predicted class labels. In a binary classification problem:\n","\n","    - TP: The number of instances where the model correctly predicted the positive class.\n","    - TN: The number of instances where the model correctly predicted the negative class.\n","    - FP: The number of instances where the model falsely predicted the positive class (actual negative instances).\n","    - FN: The number of instances where the model falsely predicted the negative class (actual positive instances)."],"metadata":{"id":"kb2KMKULjJm-"}},{"cell_type":"code","source":["# Retrieve activation function, hidden layers, and learning rate values from the first row of 'Accuracy_df_sorted'\n","Best_FiltS = int(Accuracy_df_sorted.iloc[0, 0])\n","Best_FiltN = int(Accuracy_df_sorted.iloc[0, 1])\n","Best_Strid = int(Accuracy_df_sorted.iloc[0, 2])\n","\n","# Load the best ANN model using the retrieved hyperparameters\n","best_cnn_model_name = f'CNN_FS{Best_FiltS}_FN{Best_FiltN}_St{Best_Strid}.h5'\n","best_cnn_model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/SavedFiles/ML_Models/GridSearch_CNN/' + best_cnn_model_name)\n","\n","# Predict the output (Robotic spot-welding condition) for the test data\n","Predicted = best_cnn_model.predict(TestData)\n","\n","# Convert TestLabel and Predicted into vectors to calculate the confusion matrix and evaluation metrics\n","TestLabel_rev = np.argmax(TestLabel, axis=1)\n","Predicted_rev = np.argmax(Predicted, axis=1)\n","\n","# Plot the confusion matrix\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(TestLabel_rev, Predicted_rev)\n","\n","plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap=plt.cm.Blues, cbar=False, square=True)\n","plt.xlabel(\"Predicted label\")\n","plt.ylabel(\"True label\")\n","plt.title(\"Confusion Matrix of the Best CNN Model\")\n","plt.show()"],"metadata":{"id":"FJsFsxPXnrkB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [Evaluation metrics] for the best CNN model\n","\n","1. $Accuracy$: The proportion of correctly classified instances out of the total instances. It measures the overall performance of a classification model.\n","\n","    - $Accuracy: (TP + TN) / (TP + TN + FP + FN)$\n","\n","2. $Precision$: The proportion of true positive instances among the instances predicted as positive. It measures how well the model correctly identifies positive instances.\n","\n","    - $Precision: TP / (TP + FP)$\n","\n","3. $Recall$: The proportion of true positive instances among the actual positive instances. It measures the ability of the model to find all the positive instances.\n","\n","    - $Recall: TP / (TP + FN)$\n","\n","4. $F1 Score$: The harmonic mean of precision and recall. It provides a single score that balances both precision and recall, which is especially useful when dealing with imbalanced datasets.\n","\n","    - $F1 Score: 2 * (Precision * Recall) / (Precision + Recall)$"],"metadata":{"id":"uXuaPVILnyOa"}},{"cell_type":"code","source":["from sklearn import metrics\n","\n","# Calculate the evaluation metrics\n","accuracy  = metrics.accuracy_score(TestLabel_rev, Predicted_rev)\n","precision = metrics.precision_score(TestLabel_rev, Predicted_rev)\n","recall    = metrics.recall_score(TestLabel_rev, Predicted_rev)\n","f1_score  = metrics.f1_score(TestLabel_rev, Predicted_rev)\n","\n","# Print the evaluation metrics\n","print(f\"Best CNN Model Evaluation:\\n\")\n","print(f\"Accuracy : {accuracy:.2f}\")\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall   : {recall:.2f}\")\n","print(f\"F1 Score : {f1_score:.2f}\")"],"metadata":{"id":"PDU5uRTf3LTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1ppVg-psKQ1s"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":0}